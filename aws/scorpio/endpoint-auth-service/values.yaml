## Default values for endpoint-auth-service.
## This is a YAML-formatted file.
## Declare variables to be passed into your templates.

# -- option to override the name config in the _helpers.tpl
nameOverride: ""
# -- option to override the fullname config in the _helpers.tpl
fullnameOverride: ""

## configuration to be used fo the endpoint-configuration-service
configService:

  # -- option to override the name config in the _helpers.tpl
  nameOverride: ""
  # -- option to override the fullname config in the _helpers.tpl
  fullnameOverride: ""

  ## configuration for the k8s service to access configService
  service:
    # -- service type
    type: ClusterIP
    # -- port to be used by the service
    port: 8080
    # -- addtional annotations, if required
    annotations: {}

  # -- if a configService configService service account should be used, it can be configured here
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  serviceAccount:
    # -- specifies if the account should be created
    create: false

  # -- initial number of target replications, can be different if autoscaling is enabled
  replicaCount: 1
  # -- number of old replicas to be retained
  revisionHistoryLimit: 3
  ## configuration of the configService update strategy
  updateStrategy:
    # -- type of the update
    type: RollingUpdate
    # -- new pods will be added gradually
    rollingUpdate:
      # -- number of pods that can be created above the desired amount while updating
      maxSurge: 1
      # -- number of pods that can be unavailable while updating
      maxUnavailable: 0

  ## configuration of the image to be used
  image:
    # -- endpoint-configuration-service image name
    # ref: https://quay.io/repository/fiware/endpoint-configuration-service
    repository: quay.io/fiware/endpoint-configuration-service
    # -- tag of the image to be used
    tag: 0.1.0
    # -- specification of the image pull policy
    pullPolicy: IfNotPresent

  # -- additional labels for the deployment, if required
  additionalLabels: { }
  # -- additional annotations for the deployment, if required
  additionalAnnotations: { }
  ## resource requests and limits, we leave the default empty to make that a concious choice by the user.
  ## for the autoscaling to make sense, you should configure this.
  resources: {}
    # limits:
      # cpu: 100m
      # memory: 128Mi
    # requests:
      # cpu: 100m
      # memory: 128Mi

  # -- selector template
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}

  # -- tolerations template
  # ref: ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  # -- affinity template
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}

  # -- port to request health information at
  healthPort: 9090
  ## liveness and readiness probes of the endpoint-configuration-service, they will be evaluated against the health endpoint
  # ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 30
  readinessProbe:
    initialDelaySeconds: 31
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 30

  ## pod autoscaling configuration, use for automatic scaling
  autoscaling:
    #  -- should autoscaling be enabled for configService
    enabled: false
    # -- minimum number of running pods
    minReplicas: 1
    # -- maximum number of running pods
    maxReplicas: 10
    # -- metrics to react on
    metrics: [ ]
    ## List of MetricSpecs to decide whether to scale
    # See https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#metricspec-v2beta2-autoscaling
    # scaler targets to hold average cpu around 80%
    #- type: Resource
    #  resource:
    #    name: cpu
    #     target:
    #      type: Utilization
    #      averageUtilization: 80
    ## scaler targets to hold average memory around 80%
    #  - type: Resource
    #    resource:
    #      name: memory
    #      target:
    #        type: Utilization
    #        averageUtilization: 80

  ## openshift specific route definition. Will not work on plain k8s
  route:
    ## -- should the deployment create openshift routes
    enabled: true
    # -- annotations to be added to the route
    annotations: { }
    # -- host to be used
    # host: localhost
    # -- tls configuration for the route
    tls: { }
    # termination: edge

  ## ingress configuration
  ingress:
    # -- should there be an ingress to connect configService with the public internet
    enabled: false
    # -- annotations to be added to the ingress
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # cert-manager.io/cluster-issuer: letsencrypt-prod
    # -- all hosts to be provided
    hosts: []
      # - host: ecs.fiware.dev
      ## provide a hosts and the paths that should be available
      # - host: localhost
        # paths:
          # - /
    # -- configure the ingress' tls
    tls: []
      # - secretName: ecs-tls
        # hosts:
        # - ecs.fiware.dev

  # -- port that the endpoint-configuration-service container uses
  port: 8080

  ## database configuration for endpoint-configuration-service
  db:
    # -- host of the database to be used - be aware, defaults to an in-memory db
    url: jdbc:h2:mem:devDb;LOCK_TIMEOUT=10000;DB_CLOSE_ON_EXIT=FALSE
    # -- user for connecting the database
    user: ecs
    # -- password for connecting the database
    password: pass

  ## configuration for prometheus montioring
  prometheus:
    # -- should prometheus scrape be enabled
    enabled: true
    # -- path for prometheus scrape
    path: /prometheus
    # -- port prometheus scrape is available at
    port: 9090

  # -- a list of additional env vars to be set, check the endpoint-configuration-service documentation for all available options
  additonalEnvVars: []

  # automatic updater for the configmap that represents the listener and cluster.yaml, generated by the config-service
  configmapUpdater:
    # -- should the updater be deployed?
    enabled: true
    ## configuration of the image to be used
    image:
      # -- configmap updater image name
      # ref: https://quay.io/repository/fiware/envoy-configmap-updater
      repository: quay.io/fiware/envoy-configmap-updater
      # -- tag of the image to be used
      tag: 0.1.0
      # -- specification of the image pull policy
      pullPolicy: IfNotPresent

  ## configuration for integrating the service into the openshift service mesh
  meshExtension:
    ## -- should the generation of meshExtensions be enabled?
    enabled: false
    ## -- name of the auth-provider inside the service-mesh
    authProviderName: "outbound|80||ext-authz"
    ## select the workload to apply the extension to
    workloadSelector:
      ## -- name of the selector label
      name: app
      ## -- value of the selector label
      value: app
    # additional annotations, labels and configuration for the extension can be set via configService.additonalEnvVars.
    # see the documentation of the endpoint-configuration-service for details

  ## configuration for the automatic deployment of mesh extensions
  meshExtensionUpdater:
    ## -- should the automatic update be enabled
    enabled: false
    ## image to be used for mesh-extension-updater
    image:
      # -- image name
      # ref: https://quay.io/repository/fiware/mesh-extension-updater
      repository: quay.io/fiware/mesh-extension-updater
      # -- tag of the image to be used
      tag: 0.1.0
      # -- specification of the image pull policy
      pullPolicy: IfNotPresent

## configuration for the sidecar, will be applied by the injector if not configured otherwise
sidecar:

  ## -- loglevel to be used by the sidecar, supported: [trace,debug,info,warn,error,critical,off]
  logLevel: trace

  ## -- user id to be used by the sidecar. Required to set the correct iptable rules
  userId: 1337

  ## -- port to attach envoy listener to
  port: 15001

  ## configuration of the image to be used
  image:
    # -- envoy image name
    # ref: https://quay.io/repository/fiware/envoy
    repository: quay.io/fiware/envoy
    # -- tag of the image to be used
    tag: 0.1.0
    # -- specification of the image pull policy
    pullPolicy: IfNotPresent

  ## image to be used for iptable init.
  initIptables:
    # -- image name
    # ref: https://quay.io/repository/fiware/init-iptables
    repository: quay.io/fiware/init-iptables
    # -- tag of the image to be used
    tag: 0.1.0
    # -- specification of the image pull policy
    pullPolicy: IfNotPresent

  ## image to be used for applying initial config
  initConfig:
    # -- image name
    # ref: https://quay.io/repository/fiware/envoy-resource-updater
    repository: quay.io/fiware/envoy-resource-updater
    # -- tag of the image to be used
    tag: 0.1.0
    # -- specification of the image pull policy
    pullPolicy: IfNotPresent

  ## image to be used for applying config updates
  updateConfig:
    # -- image name
    # ref: https://quay.io/repository/fiware/envoy-resource-updater
    repository: quay.io/fiware/envoy-resource-updater
    # -- tag of the image to be used
    tag: 0.1.0
    # -- specification of the image pull policy
    pullPolicy: IfNotPresent


## configuration for the automatic sidecar injection
sidecarInjector:
  ## -- should the envoy sidecar be injected into annotated pods
  enabled: true

  # -- option to override the name config in the _helpers.tpl
  nameOverride: ""
  # -- option to override the fullname config in the _helpers.tpl
  fullnameOverride: eas-sidecar-injector

  # -- if a sidecarInjector specific service account should be used, it can be configured here
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  serviceAccount:
    # -- specifies if the account should be created
    create: true

  # -- initial number of target replications, can be different if autoscaling is enabled
  replicaCount: 1
  # -- number of old replicas to be retained
  revisionHistoryLimit: 3

  ## configuration of the image to be used
  image:
    # -- sidecar-injector image name
    # ref: https://hub.docker.com/r/mayankkr/sidecarinjector
    repository: tumblr/k8s-sidecar-injector
    # -- tag of the image to be used
    tag: release-v0.5.0
    # -- specification of the image pull policy
    pullPolicy: IfNotPresent

  # -- additional labels for the deployment, if required
  additionalLabels: {}
  # -- additional annotations for the deployment, if required
  additionalAnnotations: {}

  # -- selector template
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}
  # -- tolerations template
  # ref: ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  # -- affinity template
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}

  # -- namespace of the annotation to be applied to the pod that should get injected.
  annotationNamespace: sidecar.k8s.fiware.org

  # -- namespace of the label to find the configmap to inject.
  labelNamespace: sidecar.k8s.fiware.org

  ## restriction the namespaces to apply injection
  restrictNamespace:
    # -- should the injector be restricted to labeld namespaces?
    enabled: true
    # -- label to apply to the namespaces
    label: sidecar-injection
    # -- value to be set for the label
    value: enabled

  # -- override the generated config for the sidecar, if not sufficient
  overrideSidecarconfig: {}

  # -- port that the injector listens to
  port: 8443

  # -- port that the health check is available at
  healthPort: 9000

  # -- log level of the injector
  logLevel: 2

  ## configuration for the k8s service to access configService
  service:
    # -- service type
    type: ClusterIP
    # -- port to be used by the service
    port: 443
    # -- addtional annotations, if required
    annotations: {}

  # -- certificate to be used by the injector service in pem format
  cert: |
    -----BEGIN CERTIFICATE-----
    MIIDNTCCAh2gAwIBAgIUIgb34EsQm4uQS0JiQjwid6CRXd4wDQYJKoZIhvcNAQEL
    BQAwKzEpMCcGA1UEAwwgZWFzLXNpZGVjYXItaW5qZWN0b3Iuc2NvcnBpby5zdmMw
    HhcNMjIwNzExMTQyNTE0WhcNMjcwNzEwMTQyNTE0WjArMSkwJwYDVQQDDCBlYXMt
    c2lkZWNhci1pbmplY3Rvci5zY29ycGlvLnN2YzCCASIwDQYJKoZIhvcNAQEBBQAD
    ggEPADCCAQoCggEBAOYa2hXH0SYNra4jSyKYveekRNTi6caZkqKoBRfpQGjHCncn
    57IGQm0kS1PatB2M6mif2Nvy+7XGdP0iqnaKg6Axcq0YhEQe9sA1UuwqTG0EPiYZ
    WO26aUB9srMKfAqdW2vvMPNra9tGtnW+unc5GJuwZickZitpQF9Ys5gJTwMAEMPN
    XacJTpVJD0elZN4siWOxpnrMrbbEDm6d1ogR1q7LS+kTGtrop5TdlRc09ccVwzW3
    jF+/y9jJ7GxlLSHyMNIRpC53BnSKswVLRvoLQWTBHtcGJ9gPr3GRhKx/eVhlUvcl
    XirU87yh9vaKcPlVm0pD/b30dCwTeebfQRcVT6MCAwEAAaNRME8wKwYDVR0RBCQw
    IoIgZWFzLXNpZGVjYXItaW5qZWN0b3Iuc2NvcnBpby5zdmMwCwYDVR0PBAQDAgeA
    MBMGA1UdJQQMMAoGCCsGAQUFBwMBMA0GCSqGSIb3DQEBCwUAA4IBAQCVzmTo3xYc
    e5c4ENf6NJK3DIIzcvCJ6hoobqXVEAq5tG0A4x+ObjJ89zl0mAjRMCDjuRV7kS8k
    AdOFrkERfgSZqo33JVe5J0mgug3aaINl3R2L5Y2XhZN6A3vLS7Yqf8neeXUk9Dww
    98jC+pNPOtf73yxVBjtZGyqIOqPpdheDlPwN29hiePUad14GUgY+Lw5gZoXThF1V
    dvLfZJNHZd6jI8+DKFosGuQIYrgLH7pDpHhrbZDuF352BfLcRaVIO399PoCG/82/
    u4XSHsuW68FTNF+76tBQnFqOnsuFrHZEg03x9is1fsqoQ5lm3KX7xyPUmvFRqmpy
    50J2b+9jfCx/
    -----END CERTIFICATE-----

  # -- key to be used by the injector service
  key: |
   -----BEGIN PRIVATE KEY-----
    MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDmGtoVx9EmDa2u
    I0simL3npETU4unGmZKiqAUX6UBoxwp3J+eyBkJtJEtT2rQdjOpon9jb8vu1xnT9
    Iqp2ioOgMXKtGIREHvbANVLsKkxtBD4mGVjtumlAfbKzCnwKnVtr7zDza2vbRrZ1
    vrp3ORibsGYnJGYraUBfWLOYCU8DABDDzV2nCU6VSQ9HpWTeLIljsaZ6zK22xA5u
    ndaIEdauy0vpExra6KeU3ZUXNPXHFcM1t4xfv8vYyexsZS0h8jDSEaQudwZ0irMF
    S0b6C0FkwR7XBifYD69xkYSsf3lYZVL3JV4q1PO8ofb2inD5VZtKQ/299HQsE3nm
    30EXFU+jAgMBAAECggEAUg+JbvMPt45xPgUAKppmP1Hp6jHyRQ1HqhJZnqlkevlg
    1hW5H1f0IJAs/P6l9VPn1OAMqoQBGFZqKkxOlm/XeS2pQ+nWYaTZQrrBk8+R6d71
    ewjXGhC8sG8jZ455ph9wFxH6VxUcJdsV/u/B9/q4t+00wQjOFvU2K8qqYbIQJ3UV
    YHqCrWzR7OB4k98PNFel1mnOBa8HgMQpB18iF/kephtNuII622m/8Omx9/Tn65QD
    XroaTxxDGOPHySTDIe+o4h/5i+YNfXgUJiYOYFWCPU8RxJflrpIqC4UsFE/4OVm0
    hMi4+BLgq34NhvyrX2kyNhUPIoB03Otb0rCkPDz4gQKBgQD3aeu2+YOPws6f/ERu
    i2Cl88wP1ucZAjHaJe8ilIXKlAjUZtfqn1bf5P7LhC8KpXEnW6EFEFxsqUJfQ77e
    kQZOj4F5fJgroPQZvsJNO8JThSaYmfRnztQX/1zhzhVuTxE/mP+8fId3/cKigwRD
    qJ0OXkNWvQ9u2bdlrjUpYRfBEwKBgQDuFyfC5OhgNgoJxpXPmWRVjDQ6a1KTLJQz
    MZdVoatB3ycFEihmR7L0IM1zHOpRTFyMOXP4d1FL8Gg3to3mZI1N46eRCyqBO+Pe
    CaeNJfKtQxa+oTU2vhhQtptAOq8haRUu8VhvgZI3zy9SSwRKAxPtRlppfqSI69Wm
    +QrubeeZMQKBgG30rwNkpKmRhE7pyGfwnYVjcj9f3NjqdsliroKJy2QaoknzYuYs
    5mke1nYQSu/KUx2QxWEAwnKwToUUEJHNliX39SzOyLorEBEZDDVS56xCssKDOXGh
    I/V+UgMwmamqjhnbn1xfY71aE9QxsgV3vEUUc4zq/R7gt3cDEzFOq0XtAoGBAOCm
    DolRTYVCV/RjYQWRuV8SvFEG5NIjNO6c8ysEMUAlG38oY+Al9M9uiAv+k4UEJSrW
    JvuhMZ8ShnNTF870v3Nnw7sSqxdneBkQSPzgentLGxHhsAEoGm9F7XUMKiS/LxKs
    /IGx41IvdnoSeEiRYOL4B+UUbpEW3PAAenUAVI9xAoGBAOQbwM2F7Iew/qGI5SXx
    HzPFiCXHMev+53JKtnnIF3Jt8xOqyC4zbD/YIjw79fyxFr6FtoQnCHemvmZj2j0w
    bGlFpB8Ijn9TQtNyVgKBYZAtFKCnUmNn5y2aPrqUPB9Rj58eK7HnUwt50pgWIPoy
    y85inzajncickmdqzs/99MQW
    -----END PRIVATE KEY-----

  ## liveness and readiness probes of the endpoint-configuration-service, they will be evaluated against the health endpoint
  # ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 30
  readinessProbe:
    initialDelaySeconds: 31
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 30

## configuration to be used fo the ishare-auth-provider
ishare:

  # -- should the ishare-auth-provider be enabled?
  enabled: true

  # -- option to override the name config in the _helpers.tpl
  nameOverride: ""

  # -- option to override the fullname config in the _helpers.tpl
  fullnameOverride: ""

  # -- if a ishare specific service account should be used, it can be configured here
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  serviceAccount:
    # -- specifies if the account should be created
    create: false

  # -- initial number of target replications, can be different if autoscaling is enabled
  replicaCount: 1

  # -- number of old replicas to be retained
  revisionHistoryLimit: 3

  ## configuration of the ishare update strategy
  updateStrategy:
    # -- type of the update
    type: RollingUpdate
    # -- new pods will be added gradually
    rollingUpdate:
      # -- number of pods that can be created above the desired amount while updating
      maxSurge: 1
      # -- number of pods that can be unavailable while updating
      maxUnavailable: 0

  ## configuration of the image to be used
  image:
    # -- endpoint-configuration-service image name
    # ref: https://quay.io/repository/fiware/ishare-auth-provider
    repository: quay.io/fiware/ishare-auth-provider
    # -- tag of the image to be used
    tag: 0.1.0
    # -- specification of the image pull policy
    pullPolicy: IfNotPresent

  # -- additional labels for the deployment, if required
  additionalLabels: {}

  # -- additional annotations for the deployment, if required
  additionalAnnotations: {}

  ## resource requests and limits, we leave the default empty to make that a concious choice by the user.
  ## for the autoscaling to make sense, you should configure this.
  resources: {}
    # limits:
      # cpu: 100m
      # memory: 128Mi
    # requests:
      # cpu: 100m
      # memory: 128Mi

  # -- selector template
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}

  # -- tolerations template
  # ref: ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  # -- affinity template
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}

  ## pod autoscaling configuration, use for automatic scaling
  autoscaling:
    #  -- should autoscaling be enabled for ishare
    enabled: false
    # -- minimum number of running pods
    minReplicas: 1
    # -- maximum number of running pods
    maxReplicas: 10
    # -- metrics to react on
    metrics: []
    ## List of MetricSpecs to decide whether to scale
    # See https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#metricspec-v2beta2-autoscaling
    # scaler targets to hold average cpu around 80%
    #- type: Resource
    #  resource:
    #    name: cpu
    #     target:
    #      type: Utilization
    #      averageUtilization: 80
    ## scaler targets to hold average memory around 80%
    #  - type: Resource
    #    resource:
    #      name: memory
    #      target:
    #        type: Utilization
    #        averageUtilization: 80

  ## openshift specific route definition. Will not work on plain k8s
  route:
    ## -- should the deployment create openshift routes
    enabled: true
    # -- annotations to be added to the route
    annotations: {}
    # -- host to be used
    # host: localhost
    # -- tls configuration for the route
    tls: {}
    # termination: edge

  ## ingress configuration
  ingress:
    # -- should there be an ingress to connect ishare with the public internet
    enabled: false
    # -- annotations to be added to the ingress
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # cert-manager.io/cluster-issuer: letsencrypt-prod
    # -- all hosts to be provided
    hosts: []
      # - host: ishare.fiware.dev
        ## provide a hosts and the paths that should be available
        # - host: localhost
        # paths:
          # - /
    # -- configure the ingress' tls
    tls: []
      # - secretName: ishare-tls
        # hosts:
          # - ishare.fiware.dev

  # -- port that the ishare authprovider container uses
  port: 8080

  ## configuration for the k8s service to access configService
  service:
    # -- service type
    type: ClusterIP
    # -- port to be used by the service
    port: 8080
    # -- addtional annotations, if required
    annotations: {}

  ## configuration for an Openshift ServiceMesh Entry. Only required when Openshift Service Mesh is used and the provider is not
  ## automatically included into the mesh
  serviceEntry:
    ## -- should the entry be created?
    enabled: false
    ## -- host name to be used by the mesh
    host: ext-authz
    ## -- port to access the service at
    servicePort: 80
    ## -- Address to the service. This could either be a kubernetes service or an external address. See the ossm documentation for details.
    address: ishare-authprovider
    ## -- port to access the auth-provider at
    providerPort: 8080

  storage:
    # -- should the config be persisted inside a pvc
    enabled: true
    # -- how big should the pvc be
    size: 8G

## address of the auth-provider. For now, this will be ishare. If multiple are used, this should point to a path-based router to distribute the requests.
authProvider:
  # -- address to the auth-service
  address: ishare-auth
  # -- port of the auth-service
  port: 8080
